{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a234f5c1-2fa9-4e7b-836d-a02d24a49e52",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset_malwares.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 334\u001b[39m\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m analyzer\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    333\u001b[39m     \u001b[38;5;66;03m# Run the complete analysis\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m     analyzer = \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m     \u001b[38;5;66;03m# Optional: Save results\u001b[39;00m\n\u001b[32m    337\u001b[39m     \u001b[38;5;66;03m# results_df = pd.DataFrame({\u001b[39;00m\n\u001b[32m    338\u001b[39m     \u001b[38;5;66;03m#     'Sample_Name': analyzer.df['Name'] if 'Name' in analyzer.df.columns else range(len(analyzer.cluster_labels)),\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    342\u001b[39m     \u001b[38;5;66;03m# results_df.to_csv('clustering_results.csv', index=False)\u001b[39;00m\n\u001b[32m    343\u001b[39m     \u001b[38;5;66;03m# print(\"\\nResults saved to 'clustering_results.csv'\")\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 302\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m    301\u001b[39m     \u001b[38;5;66;03m# Initialize analyzer\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m302\u001b[39m     analyzer = \u001b[43mMalwareKMeansAnalyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdataset_malwares.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    304\u001b[39m     \u001b[38;5;66;03m# Step 1: Load and explore data\u001b[39;00m\n\u001b[32m    305\u001b[39m     sample_data = analyzer.load_and_explore_data()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mMalwareKMeansAnalyzer.__init__\u001b[39m\u001b[34m(self, csv_file_path)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, csv_file_path):\n\u001b[32m     16\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Initialize the analyzer with the dataset\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28mself\u001b[39m.df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28mself\u001b[39m.scaler = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     19\u001b[39m     \u001b[38;5;28mself\u001b[39m.kmeans_model = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/aics/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/aics/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/aics/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/aics/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/aics/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'dataset_malwares.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "csv_file_path = '/Users/sfsmith/AICS/Antimalware/dataset_malwares.csv'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class MalwareKMeansAnalyzer:\n",
    "    def __init__(self, csv_file_path):\n",
    "        \"\"\"Initialize the analyzer with the dataset\"\"\"\n",
    "        self.df = pd.read_csv(csv_file_path)\n",
    "        self.scaler = None\n",
    "        self.kmeans_model = None\n",
    "        self.pca_model = None\n",
    "        self.X_scaled = None\n",
    "        self.X_pca = None\n",
    "        self.cluster_labels = None\n",
    "        \n",
    "    def load_and_explore_data(self):\n",
    "        \"\"\"Load and explore the dataset\"\"\"\n",
    "        print(\"=== Dataset Overview ===\")\n",
    "        print(f\"Dataset shape: {self.df.shape}\")\n",
    "        print(f\"Columns: {list(self.df.columns)}\")\n",
    "        \n",
    "        # Check for missing values\n",
    "        missing_vals = self.df.isnull().sum()\n",
    "        if missing_vals.sum() > 0:\n",
    "            print(f\"\\nMissing values found:\")\n",
    "            print(missing_vals[missing_vals > 0])\n",
    "        else:\n",
    "            print(\"\\nNo missing values found!\")\n",
    "            \n",
    "        # Target distribution\n",
    "        if 'Malware' in self.df.columns:\n",
    "            malware_dist = self.df['Malware'].value_counts()\n",
    "            print(f\"\\nMalware distribution:\")\n",
    "            print(f\"Benign (0): {malware_dist.get(0, 0)}\")\n",
    "            print(f\"Malware (1): {malware_dist.get(1, 0)}\")\n",
    "            \n",
    "        return self.df.head()\n",
    "    \n",
    "    def preprocess_data(self):\n",
    "        \"\"\"Preprocess the data for clustering\"\"\"\n",
    "        print(\"\\n=== Data Preprocessing ===\")\n",
    "        \n",
    "        # Separate features from target and identifier\n",
    "        exclude_cols = ['Name', 'Malware'] if 'Name' in self.df.columns else ['Malware']\n",
    "        if 'Malware' in self.df.columns:\n",
    "            self.y_true = self.df['Malware'].values\n",
    "        \n",
    "        # Select numeric features only\n",
    "        numeric_cols = self.df.select_dtypes(include=[np.number]).columns\n",
    "        feature_cols = [col for col in numeric_cols if col not in exclude_cols]\n",
    "        \n",
    "        self.X = self.df[feature_cols].copy()\n",
    "        print(f\"Selected {len(feature_cols)} numeric features for clustering\")\n",
    "        \n",
    "        # Handle any remaining missing values\n",
    "        self.X = self.X.fillna(self.X.median())\n",
    "        \n",
    "        # Scale the features using RobustScaler (less sensitive to outliers)\n",
    "        self.scaler = RobustScaler()\n",
    "        self.X_scaled = self.scaler.fit_transform(self.X)\n",
    "        \n",
    "        print(\"Data preprocessing completed!\")\n",
    "        return self.X_scaled\n",
    "    \n",
    "    def find_optimal_clusters(self, max_k=10):\n",
    "        \"\"\"Find optimal number of clusters using elbow method and silhouette analysis\"\"\"\n",
    "        print(f\"\\n=== Finding Optimal Number of Clusters (k=1 to {max_k}) ===\")\n",
    "        \n",
    "        inertias = []\n",
    "        silhouette_scores = []\n",
    "        k_range = range(2, max_k + 1)\n",
    "        \n",
    "        # Calculate metrics for different k values\n",
    "        for k in k_range:\n",
    "            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "            cluster_labels = kmeans.fit_predict(self.X_scaled)\n",
    "            \n",
    "            inertias.append(kmeans.inertia_)\n",
    "            sil_score = silhouette_score(self.X_scaled, cluster_labels)\n",
    "            silhouette_scores.append(sil_score)\n",
    "            \n",
    "            print(f\"k={k}: Inertia={kmeans.inertia_:.2f}, Silhouette Score={sil_score:.3f}\")\n",
    "        \n",
    "        # Plot elbow curve and silhouette scores\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Elbow method\n",
    "        ax1.plot(k_range, inertias, 'bo-')\n",
    "        ax1.set_xlabel('Number of Clusters (k)')\n",
    "        ax1.set_ylabel('Inertia')\n",
    "        ax1.set_title('Elbow Method for Optimal k')\n",
    "        ax1.grid(True)\n",
    "        \n",
    "        # Silhouette scores\n",
    "        ax2.plot(k_range, silhouette_scores, 'ro-')\n",
    "        ax2.set_xlabel('Number of Clusters (k)')\n",
    "        ax2.set_ylabel('Silhouette Score')\n",
    "        ax2.set_title('Silhouette Analysis')\n",
    "        ax2.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Find optimal k (highest silhouette score)\n",
    "        optimal_k = k_range[np.argmax(silhouette_scores)]\n",
    "        print(f\"\\nOptimal number of clusters based on silhouette score: k={optimal_k}\")\n",
    "        \n",
    "        return optimal_k, silhouette_scores\n",
    "    \n",
    "    def perform_clustering(self, n_clusters=None):\n",
    "        \"\"\"Perform K-means clustering\"\"\"\n",
    "        if n_clusters is None:\n",
    "            n_clusters, _ = self.find_optimal_clusters()\n",
    "        \n",
    "        print(f\"\\n=== Performing K-means Clustering (k={n_clusters}) ===\")\n",
    "        \n",
    "        # Fit K-means\n",
    "        self.kmeans_model = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "        self.cluster_labels = self.kmeans_model.fit_predict(self.X_scaled)\n",
    "        \n",
    "        # Calculate clustering metrics\n",
    "        silhouette_avg = silhouette_score(self.X_scaled, self.cluster_labels)\n",
    "        inertia = self.kmeans_model.inertia_\n",
    "        \n",
    "        print(f\"Clustering completed!\")\n",
    "        print(f\"Silhouette Score: {silhouette_avg:.3f}\")\n",
    "        print(f\"Inertia: {inertia:.2f}\")\n",
    "        \n",
    "        # Cluster distribution\n",
    "        unique, counts = np.unique(self.cluster_labels, return_counts=True)\n",
    "        print(\"\\nCluster distribution:\")\n",
    "        for cluster_id, count in zip(unique, counts):\n",
    "            print(f\"Cluster {cluster_id}: {count} samples ({count/len(self.cluster_labels)*100:.1f}%)\")\n",
    "        \n",
    "        return self.cluster_labels\n",
    "    \n",
    "    def analyze_clusters_vs_malware(self):\n",
    "        \"\"\"Analyze how clusters relate to malware labels\"\"\"\n",
    "        if not hasattr(self, 'y_true'):\n",
    "            print(\"No malware labels available for comparison\")\n",
    "            return\n",
    "            \n",
    "        print(\"\\n=== Cluster vs Malware Analysis ===\")\n",
    "        \n",
    "        # Create confusion matrix-like analysis\n",
    "        cluster_malware_df = pd.DataFrame({\n",
    "            'Cluster': self.cluster_labels,\n",
    "            'Malware': self.y_true\n",
    "        })\n",
    "        \n",
    "        # Cross-tabulation\n",
    "        crosstab = pd.crosstab(cluster_malware_df['Cluster'], \n",
    "                              cluster_malware_df['Malware'], \n",
    "                              margins=True)\n",
    "        print(\"Cluster vs Malware Cross-tabulation:\")\n",
    "        print(crosstab)\n",
    "        \n",
    "        # Calculate purity of each cluster\n",
    "        print(\"\\nCluster Purity Analysis:\")\n",
    "        for cluster_id in np.unique(self.cluster_labels):\n",
    "            cluster_mask = self.cluster_labels == cluster_id\n",
    "            cluster_malware = self.y_true[cluster_mask]\n",
    "            \n",
    "            total_in_cluster = len(cluster_malware)\n",
    "            malware_in_cluster = np.sum(cluster_malware)\n",
    "            benign_in_cluster = total_in_cluster - malware_in_cluster\n",
    "            \n",
    "            malware_purity = malware_in_cluster / total_in_cluster * 100\n",
    "            benign_purity = benign_in_cluster / total_in_cluster * 100\n",
    "            \n",
    "            print(f\"Cluster {cluster_id}: {malware_purity:.1f}% malware, {benign_purity:.1f}% benign\")\n",
    "        \n",
    "        # Calculate Adjusted Rand Index\n",
    "        ari_score = adjusted_rand_score(self.y_true, self.cluster_labels)\n",
    "        print(f\"\\nAdjusted Rand Index: {ari_score:.3f}\")\n",
    "        \n",
    "        return crosstab\n",
    "    \n",
    "    def visualize_clusters_pca(self):\n",
    "        \"\"\"Visualize clusters using PCA\"\"\"\n",
    "        print(\"\\n=== Creating PCA Visualization ===\")\n",
    "        \n",
    "        # Apply PCA for visualization\n",
    "        self.pca_model = PCA(n_components=2, random_state=42)\n",
    "        self.X_pca = self.pca_model.fit_transform(self.X_scaled)\n",
    "        \n",
    "        explained_variance = self.pca_model.explained_variance_ratio_\n",
    "        print(f\"PCA Explained Variance: PC1={explained_variance[0]:.3f}, PC2={explained_variance[1]:.3f}\")\n",
    "        print(f\"Total Explained Variance: {sum(explained_variance):.3f}\")\n",
    "        \n",
    "        # Create subplots\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        # Plot 1: Clusters\n",
    "        scatter1 = axes[0].scatter(self.X_pca[:, 0], self.X_pca[:, 1], \n",
    "                                  c=self.cluster_labels, cmap='viridis', alpha=0.6)\n",
    "        axes[0].set_xlabel(f'PC1 ({explained_variance[0]:.1%} variance)')\n",
    "        axes[0].set_ylabel(f'PC2 ({explained_variance[1]:.1%} variance)')\n",
    "        axes[0].set_title('K-means Clusters (PCA Visualization)')\n",
    "        plt.colorbar(scatter1, ax=axes[0], label='Cluster')\n",
    "        \n",
    "        # Plot cluster centers\n",
    "        centers_pca = self.pca_model.transform(self.scaler.inverse_transform(\n",
    "            self.kmeans_model.cluster_centers_))\n",
    "        centers_pca = self.pca_model.transform(self.scaler.fit_transform(\n",
    "            self.scaler.inverse_transform(self.kmeans_model.cluster_centers_)))\n",
    "        \n",
    "        # Plot 2: True labels (if available)\n",
    "        if hasattr(self, 'y_true'):\n",
    "            scatter2 = axes[1].scatter(self.X_pca[:, 0], self.X_pca[:, 1], \n",
    "                                      c=self.y_true, cmap='RdYlBu', alpha=0.6)\n",
    "            axes[1].set_xlabel(f'PC1 ({explained_variance[0]:.1%} variance)')\n",
    "            axes[1].set_ylabel(f'PC2 ({explained_variance[1]:.1%} variance)')\n",
    "            axes[1].set_title('True Labels (Malware vs Benign)')\n",
    "            cbar2 = plt.colorbar(scatter2, ax=axes[1])\n",
    "            cbar2.set_ticks([0, 1])\n",
    "            cbar2.set_ticklabels(['Benign', 'Malware'])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def feature_importance_analysis(self):\n",
    "        \"\"\"Analyze which features are most important for clustering\"\"\"\n",
    "        print(\"\\n=== Feature Importance Analysis ===\")\n",
    "        \n",
    "        # Calculate cluster centers in original feature space\n",
    "        cluster_centers = self.scaler.inverse_transform(self.kmeans_model.cluster_centers_)\n",
    "        \n",
    "        # Calculate variance across cluster centers for each feature\n",
    "        feature_variance = np.var(cluster_centers, axis=0)\n",
    "        feature_names = self.X.columns\n",
    "        \n",
    "        # Sort features by importance\n",
    "        importance_idx = np.argsort(feature_variance)[::-1]\n",
    "        \n",
    "        print(\"Top 15 most discriminative features:\")\n",
    "        for i in range(min(15, len(feature_names))):\n",
    "            idx = importance_idx[i]\n",
    "            print(f\"{i+1:2d}. {feature_names[idx]:30s}: {feature_variance[idx]:.2e}\")\n",
    "        \n",
    "        # Visualize top features\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        top_n = min(20, len(feature_names))\n",
    "        y_pos = np.arange(top_n)\n",
    "        \n",
    "        plt.barh(y_pos, feature_variance[importance_idx[:top_n]])\n",
    "        plt.yticks(y_pos, [feature_names[importance_idx[i]] for i in range(top_n)])\n",
    "        plt.xlabel('Variance Across Cluster Centers')\n",
    "        plt.title('Top 20 Most Discriminative Features for Clustering')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def generate_summary_report(self):\n",
    "        \"\"\"Generate a comprehensive summary report\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"MALWARE K-MEANS CLUSTERING ANALYSIS SUMMARY\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        if self.kmeans_model is not None:\n",
    "            n_clusters = self.kmeans_model.n_clusters\n",
    "            silhouette_avg = silhouette_score(self.X_scaled, self.cluster_labels)\n",
    "            \n",
    "            print(f\"Dataset: {self.df.shape[0]} samples, {self.X.shape[1]} features\")\n",
    "            print(f\"Number of clusters: {n_clusters}\")\n",
    "            print(f\"Silhouette Score: {silhouette_avg:.3f}\")\n",
    "            print(f\"Inertia: {self.kmeans_model.inertia_:.2f}\")\n",
    "            \n",
    "            if hasattr(self, 'y_true'):\n",
    "                ari_score = adjusted_rand_score(self.y_true, self.cluster_labels)\n",
    "                print(f\"Adjusted Rand Index: {ari_score:.3f}\")\n",
    "                \n",
    "                # Dominant class in each cluster\n",
    "                print(f\"\\nCluster Composition:\")\n",
    "                for cluster_id in range(n_clusters):\n",
    "                    cluster_mask = self.cluster_labels == cluster_id\n",
    "                    cluster_malware = self.y_true[cluster_mask]\n",
    "                    malware_pct = np.mean(cluster_malware) * 100\n",
    "                    total_samples = np.sum(cluster_mask)\n",
    "                    dominant_class = \"Malware\" if malware_pct > 50 else \"Benign\"\n",
    "                    print(f\"  Cluster {cluster_id}: {total_samples:5d} samples, \"\n",
    "                          f\"{malware_pct:5.1f}% malware ({dominant_class} dominant)\")\n",
    "        \n",
    "        print(\"\\nRecommendations:\")\n",
    "        print(\"- Use the identified clusters for malware family detection\")\n",
    "        print(\"- Investigate samples in mixed clusters for potential new threats\")\n",
    "        print(\"- Focus on discriminative features for improved detection models\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "# Example usage and main execution\n",
    "def main():\n",
    "    # Initialize analyzer\n",
    "    analyzer = MalwareKMeansAnalyzer('dataset_malwares.csv')\n",
    "    \n",
    "    # Step 1: Load and explore data\n",
    "    sample_data = analyzer.load_and_explore_data()\n",
    "    print(\"\\nSample data:\")\n",
    "    print(sample_data)\n",
    "    \n",
    "    # Step 2: Preprocess data\n",
    "    X_scaled = analyzer.preprocess_data()\n",
    "    \n",
    "    # Step 3: Find optimal number of clusters\n",
    "    optimal_k, silhouette_scores = analyzer.find_optimal_clusters(max_k=8)\n",
    "    \n",
    "    # Step 4: Perform clustering with optimal k\n",
    "    cluster_labels = analyzer.perform_clustering(n_clusters=optimal_k)\n",
    "    \n",
    "    # Step 5: Analyze clusters vs malware labels\n",
    "    crosstab = analyzer.analyze_clusters_vs_malware()\n",
    "    \n",
    "    # Step 6: Visualize clusters\n",
    "    analyzer.visualize_clusters_pca()\n",
    "    \n",
    "    # Step 7: Feature importance analysis\n",
    "    analyzer.feature_importance_analysis()\n",
    "    \n",
    "    # Step 8: Generate summary report\n",
    "    analyzer.generate_summary_report()\n",
    "    \n",
    "    return analyzer\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the complete analysis\n",
    "    analyzer = main()\n",
    "    \n",
    "    # Optional: Save results\n",
    "    # results_df = pd.DataFrame({\n",
    "    #     'Sample_Name': analyzer.df['Name'] if 'Name' in analyzer.df.columns else range(len(analyzer.cluster_labels)),\n",
    "    #     'Cluster': analyzer.cluster_labels,\n",
    "    #     'True_Label': analyzer.y_true if hasattr(analyzer, 'y_true') else None\n",
    "    # })\n",
    "    # results_df.to_csv('clustering_results.csv', index=False)\n",
    "    # print(\"\\nResults saved to 'clustering_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0867107-d155-4825-8105-f512c2e41339",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
