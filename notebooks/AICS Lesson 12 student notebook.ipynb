{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4643321d-3779-4273-a1a5-3d8bbc74f40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class 12: Natural Language Processing (NLP) for Security\n",
    "# Student Practice Notebook - Machine Learning Lifecycle Demonstration \n",
    "\n",
    "\"\"\"\n",
    "Learning Objectives:\n",
    "1. Understand the ML lifecycle for NLP in security contexts\n",
    "2. Practice text preprocessing techniques\n",
    "3. Apply sentiment analysis to security data\n",
    "4. Implement topic modeling for threat intelligence\n",
    "5. Build a simple security text classifier\n",
    "\n",
    "This notebook uses synthetic data to demonstrate concepts safely.\n",
    "\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 1: SETUP AND IMPORTS\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK data\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "except LookupError:\n",
    "    nltk.download('wordnet')\n",
    "\n",
    "print(\"✅ All imports successful!\")\n",
    "print(\"📚 Class 12: NLP for Security - Practice Notebook (Fixed)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e35b630-8359-4340-ba9e-2fe44955a98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 2: PROBLEM DEFINITION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n🎯 STEP 2: PROBLEM DEFINITION\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "problem_statement = \"\"\"\n",
    "BUSINESS PROBLEM:\n",
    "Our Security Operations Center (SOC) receives thousands of text-based security alerts,\n",
    "incident reports, and threat intelligence feeds daily. Manual analysis is:\n",
    "- Time-consuming (45+ minutes per incident)\n",
    "- Inconsistent (different analysts, different interpretations)\n",
    "- Error-prone (human fatigue, information overload)\n",
    "- Not scalable (volume growing 20% yearly)\n",
    "\n",
    "TECHNICAL OBJECTIVES:\n",
    "1. Automatically classify security incidents by severity and type\n",
    "2. Extract key entities (IPs, domains, malware families) from text\n",
    "3. Perform sentiment analysis on threat intelligence\n",
    "4. Discover hidden topics in security data\n",
    "5. Reduce analyst workload by 70%\n",
    "\n",
    "SUCCESS METRICS:\n",
    "- Classification accuracy > 85%\n",
    "- Processing time < 1 second per document\n",
    "- False positive rate < 10%\n",
    "- Analyst satisfaction score > 4/5\n",
    "\"\"\"\n",
    "\n",
    "print(problem_statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb57c105-61c1-42be-a989-233269be0e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 3: SYNTHETIC DATA GENERATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n📊 STEP 3: SYNTHETIC DATA GENERATION\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Generate synthetic security incident data\n",
    "np.random.seed(42)  # For reproducible results\n",
    "\n",
    "# Security incident templates\n",
    "incident_templates = {\n",
    "    'malware': [\n",
    "        \"Malware detected on endpoint {hostname}. User {user} may be infected. {malware_family} signature found.\",\n",
    "        \"Suspicious file {filename} quarantined from {hostname}. Possible {malware_family} infection.\",\n",
    "        \"Antivirus alert: {malware_family} detected in {location}. User {user} affected.\",\n",
    "        \"Endpoint protection blocked {malware_family} execution on {hostname}. Immediate action required.\",\n",
    "        \"Ransomware encryption detected on {hostname}. {malware_family} variant identified.\"\n",
    "    ],\n",
    "    'network': [\n",
    "        \"Suspicious network traffic detected from {ip_source} to {ip_dest} on port {port}.\",\n",
    "        \"Potential data exfiltration: Large file transfer from {hostname} to external IP {ip_dest}.\",\n",
    "        \"DDoS attack detected: High volume traffic from {ip_source}. {attack_size} requests per second.\",\n",
    "        \"Port scan detected from {ip_source}. Multiple ports targeted on {hostname}.\",\n",
    "        \"Firewall blocked {blocked_count} connection attempts from {ip_source}.\"\n",
    "    ],\n",
    "    'phishing': [\n",
    "        \"Phishing email detected from {sender}. Subject: {subject}. {user_count} users targeted.\",\n",
    "        \"Suspicious email campaign: {user_count} users received emails from {sender}.\",\n",
    "        \"Email security alert: Malicious attachment in email from {sender} to {user}.\",\n",
    "        \"Credential harvesting attempt detected. Fake {service} login page reported.\",\n",
    "        \"Business Email Compromise suspected. Fraudulent email from {sender} requesting wire transfer.\"\n",
    "    ],\n",
    "    'vulnerability': [\n",
    "        \"Critical vulnerability {cve} discovered in {software}. Patch required immediately.\",\n",
    "        \"Vulnerability scan completed. {vuln_count} high-risk vulnerabilities found on {hostname}.\",\n",
    "        \"Zero-day exploit detected targeting {software}. {cve} affects version {version}.\",\n",
    "        \"Security patch required: {software} version {version} vulnerable to {attack_type}.\",\n",
    "        \"Penetration test identified {vuln_count} vulnerabilities in {service}.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Generate sample data\n",
    "def generate_security_incidents(n_samples=500):\n",
    "    incidents = []\n",
    "    \n",
    "    # Sample values for templates\n",
    "    hostnames = ['SRV-WEB-01', 'WS-FINANCE-05', 'DB-PROD-02', 'LAPTOP-HR-12', 'SRV-EMAIL-01']\n",
    "    users = ['john.doe', 'sarah.smith', 'mike.jones', 'lisa.wang', 'admin']\n",
    "    malware_families = ['Emotet', 'TrickBot', 'Ryuk', 'Cobalt Strike', 'Mimikatz']\n",
    "    ip_addresses = ['192.168.1.100', '10.0.0.50', '203.0.113.5', '198.51.100.10']\n",
    "    ports = ['3389', '22', '80', '443', '445', '135']\n",
    "    cves = ['CVE-2021-44228', 'CVE-2021-34527', 'CVE-2020-1472', 'CVE-2021-26855']\n",
    "    software = ['Apache Log4j', 'Microsoft Exchange', 'Windows Server', 'Adobe Flash']\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # Randomly select incident type\n",
    "        incident_type = np.random.choice(list(incident_templates.keys()))\n",
    "        template = np.random.choice(incident_templates[incident_type])\n",
    "        \n",
    "        # Fill template with random values\n",
    "        incident_text = template.format(\n",
    "            hostname=np.random.choice(hostnames),\n",
    "            user=np.random.choice(users),\n",
    "            malware_family=np.random.choice(malware_families),\n",
    "            filename=f\"suspicious_file_{np.random.randint(1,100)}.exe\",\n",
    "            location=\"C:\\\\Users\\\\Downloads\\\\\",\n",
    "            ip_source=np.random.choice(ip_addresses),\n",
    "            ip_dest=np.random.choice(ip_addresses),\n",
    "            port=np.random.choice(ports),\n",
    "            attack_size=np.random.randint(1000, 10000),\n",
    "            blocked_count=np.random.randint(50, 500),\n",
    "            sender=f\"attacker{np.random.randint(1,20)}@malicious-domain.com\",\n",
    "            subject=\"Urgent: Account Verification Required\",\n",
    "            user_count=np.random.randint(5, 50),\n",
    "            service=np.random.choice(['Office365', 'Gmail', 'PayPal', 'Banking']),\n",
    "            cve=np.random.choice(cves),\n",
    "            software=np.random.choice(software),\n",
    "            vuln_count=np.random.randint(1, 15),\n",
    "            version=f\"{np.random.randint(1,5)}.{np.random.randint(0,9)}\",\n",
    "            attack_type=np.random.choice(['RCE', 'XSS', 'SQLi', 'Buffer Overflow'])\n",
    "        )\n",
    "        \n",
    "        # Assign severity based on incident type\n",
    "        severity_mapping = {\n",
    "            'malware': np.random.choice(['High', 'Critical'], p=[0.7, 0.3]),\n",
    "            'network': np.random.choice(['Medium', 'High'], p=[0.6, 0.4]),\n",
    "            'phishing': np.random.choice(['Medium', 'High'], p=[0.8, 0.2]),\n",
    "            'vulnerability': np.random.choice(['High', 'Critical'], p=[0.5, 0.5])\n",
    "        }\n",
    "        \n",
    "        incidents.append({\n",
    "            'incident_id': f'INC-{i+1:04d}',\n",
    "            'text': incident_text,\n",
    "            'type': incident_type,\n",
    "            'severity': severity_mapping[incident_type],\n",
    "            'timestamp': pd.Timestamp.now() - pd.Timedelta(days=np.random.randint(0, 30))\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(incidents)\n",
    "\n",
    "# Generate phishing vs legitimate email data\n",
    "def generate_email_data(n_samples=200):\n",
    "    emails = []\n",
    "    \n",
    "    # Phishing email templates (negative sentiment, urgency)\n",
    "    phishing_templates = [\n",
    "        \"URGENT: Your account will be suspended in 24 hours! Click here immediately to verify.\",\n",
    "        \"Security Alert: Suspicious activity detected. Verify your identity NOW or lose access.\",\n",
    "        \"Final Notice: Payment overdue. Click to avoid legal action.\",\n",
    "        \"Your account has been compromised! Change password immediately at this link.\",\n",
    "        \"Congratulations! You've won $10,000! Claim your prize before it expires.\"\n",
    "    ]\n",
    "    \n",
    "    # Legitimate email templates (neutral/positive sentiment)\n",
    "    legitimate_templates = [\n",
    "        \"Thank you for your recent order. Your package will arrive in 3-5 business days.\",\n",
    "        \"Your monthly security report is ready for review. Please find attached.\",\n",
    "        \"Reminder: Team meeting scheduled for tomorrow at 2 PM in conference room A.\",\n",
    "        \"Software update available. Please install during your next maintenance window.\",\n",
    "        \"Your backup completed successfully. All files are secure and accessible.\"\n",
    "    ]\n",
    "    \n",
    "    # Generate phishing emails\n",
    "    for i in range(n_samples // 2):\n",
    "        emails.append({\n",
    "            'email_id': f'EMAIL-{i+1:04d}',\n",
    "            'text': np.random.choice(phishing_templates),\n",
    "            'label': 'phishing',\n",
    "            'sentiment': 'negative'\n",
    "        })\n",
    "    \n",
    "    # Generate legitimate emails\n",
    "    for i in range(n_samples // 2, n_samples):\n",
    "        emails.append({\n",
    "            'email_id': f'EMAIL-{i+1:04d}',\n",
    "            'text': np.random.choice(legitimate_templates),\n",
    "            'label': 'legitimate',\n",
    "            'sentiment': 'neutral'\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(emails)\n",
    "\n",
    "# Generate threat intelligence reports\n",
    "def generate_threat_intel(n_samples=100):\n",
    "    reports = []\n",
    "    \n",
    "    threat_templates = [\n",
    "        \"APT29 observed using {tool} to target {sector} organizations. {ioc_count} IOCs identified.\",\n",
    "        \"New {malware} campaign targeting {sector}. Distributed via {vector}.\",\n",
    "        \"Vulnerability {cve} actively exploited by {group}. {affected_count} organizations at risk.\",\n",
    "        \"Ransomware group {group} demands ${ransom_amount} from {sector} victims.\",\n",
    "        \"Nation-state actor {group} conducting espionage against {sector} using {technique}.\"\n",
    "    ]\n",
    "    \n",
    "    tools = ['Cobalt Strike', 'Metasploit', 'Empire', 'PowerShell', 'Living off the Land']\n",
    "    sectors = ['healthcare', 'finance', 'government', 'education', 'manufacturing']\n",
    "    groups = ['APT29', 'APT28', 'Lazarus', 'FIN7', 'Carbanak']\n",
    "    vectors = ['phishing emails', 'watering hole attacks', 'supply chain compromise']\n",
    "    techniques = ['spear phishing', 'credential stuffing', 'lateral movement']\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        report_text = np.random.choice(threat_templates).format(\n",
    "            tool=np.random.choice(tools),\n",
    "            sector=np.random.choice(sectors),\n",
    "            ioc_count=np.random.randint(5, 50),\n",
    "            malware=f\"Malware-{np.random.randint(1,10)}\",\n",
    "            vector=np.random.choice(vectors),\n",
    "            cve=f\"CVE-2024-{np.random.randint(1000, 9999)}\",\n",
    "            group=np.random.choice(groups),\n",
    "            affected_count=np.random.randint(10, 1000),\n",
    "            ransom_amount=np.random.choice([1, 2, 5, 10]) * 1000000,\n",
    "            technique=np.random.choice(techniques)\n",
    "        )\n",
    "        \n",
    "        reports.append({\n",
    "            'report_id': f'TI-{i+1:04d}',\n",
    "            'text': report_text,\n",
    "            'source': np.random.choice(['OSINT', 'Commercial', 'Government', 'Internal']),\n",
    "            'confidence': np.random.choice(['Low', 'Medium', 'High'])\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(reports)\n",
    "\n",
    "# Generate all datasets\n",
    "print(\"Generating synthetic security datasets...\")\n",
    "incidents_df = generate_security_incidents(500)\n",
    "emails_df = generate_email_data(200)\n",
    "threat_intel_df = generate_threat_intel(100)\n",
    "\n",
    "print(f\"✅ Generated {len(incidents_df)} security incidents\")\n",
    "print(f\"✅ Generated {len(emails_df)} email samples\")\n",
    "print(f\"✅ Generated {len(threat_intel_df)} threat intelligence reports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3942bf79-fa14-4294-8571-04b7837ad713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 4: EXPLORATORY DATA ANALYSIS (EDA)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n🔍 STEP 4: EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"SECURITY INCIDENTS DATASET:\")\n",
    "print(f\"Shape: {incidents_df.shape}\")\n",
    "print(f\"Columns: {list(incidents_df.columns)}\")\n",
    "print(\"\\nIncident Type Distribution:\")\n",
    "print(incidents_df['type'].value_counts())\n",
    "print(\"\\nSeverity Distribution:\")\n",
    "print(incidents_df['severity'].value_counts())\n",
    "\n",
    "print(\"\\nEMAIL DATASET:\")\n",
    "print(f\"Shape: {emails_df.shape}\")\n",
    "print(f\"Columns: {list(emails_df.columns)}\")\n",
    "print(\"\\nEmail Label Distribution:\")\n",
    "print(emails_df['label'].value_counts())\n",
    "\n",
    "# Sample data preview\n",
    "print(\"\\nSAMPLE SECURITY INCIDENTS:\")\n",
    "for i, row in incidents_df.head(3).iterrows():\n",
    "    print(f\"\\nIncident {row['incident_id']} ({row['type']}, {row['severity']}):\")\n",
    "    print(f\"Text: {row['text']}\")\n",
    "\n",
    "print(\"\\nSAMPLE EMAILS:\")\n",
    "for i, row in emails_df.head(2).iterrows():\n",
    "    print(f\"\\nEmail {row['email_id']} ({row['label']}):\")\n",
    "    print(f\"Text: {row['text']}\")\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Incident type distribution\n",
    "incidents_df['type'].value_counts().plot(kind='bar', ax=axes[0,0], color='skyblue')\n",
    "axes[0,0].set_title('Security Incident Types')\n",
    "axes[0,0].set_xlabel('Incident Type')\n",
    "axes[0,0].set_ylabel('Count')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Severity distribution\n",
    "incidents_df['severity'].value_counts().plot(kind='pie', ax=axes[0,1], autopct='%1.1f%%')\n",
    "axes[0,1].set_title('Incident Severity Distribution')\n",
    "\n",
    "# Email classification\n",
    "emails_df['label'].value_counts().plot(kind='bar', ax=axes[1,0], color=['red', 'green'])\n",
    "axes[1,0].set_title('Email Classification')\n",
    "axes[1,0].set_xlabel('Email Type')\n",
    "axes[1,0].set_ylabel('Count')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Text length distribution\n",
    "text_lengths = incidents_df['text'].str.len()\n",
    "axes[1,1].hist(text_lengths, bins=20, color='lightcoral', alpha=0.7)\n",
    "axes[1,1].set_title('Incident Text Length Distribution')\n",
    "axes[1,1].set_xlabel('Text Length (characters)')\n",
    "axes[1,1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167f3aff-ddd4-4782-957d-0a42c173e662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 5: TEXT PREPROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n🧹 STEP 5: TEXT PREPROCESSING\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Initialize preprocessing tools\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Custom security stop words (domain-specific)\n",
    "security_stop_words = {\n",
    "    'alert', 'detected', 'found', 'system', 'user', 'file', 'server', \n",
    "    'network', 'security', 'incident', 'report', 'please', 'immediate'\n",
    "}\n",
    "stop_words.update(security_stop_words)\n",
    "\n",
    "def preprocess_text(text, use_stemming=True, remove_stopwords=True):\n",
    "    \"\"\"\n",
    "    Comprehensive text preprocessing function for security text\n",
    "    \"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters but keep important security patterns\n",
    "    # Keep IPs, domains, CVE IDs, file extensions\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s\\-\\._]', ' ', text)\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    if remove_stopwords:\n",
    "        tokens = [token for token in tokens if token not in stop_words and len(token) > 2]\n",
    "    \n",
    "    # Stemming or lemmatization\n",
    "    if use_stemming:\n",
    "        tokens = [stemmer.stem(token) for token in tokens]\n",
    "    else:\n",
    "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Demonstrate preprocessing steps\n",
    "sample_text = incidents_df.iloc[0]['text']\n",
    "print(\"PREPROCESSING DEMONSTRATION:\")\n",
    "print(f\"Original text: {sample_text}\")\n",
    "print()\n",
    "\n",
    "# Step by step preprocessing\n",
    "print(\"Step 1 - Lowercase:\")\n",
    "step1 = sample_text.lower()\n",
    "print(step1)\n",
    "print()\n",
    "\n",
    "print(\"Step 2 - Remove special characters:\")\n",
    "step2 = re.sub(r'[^a-zA-Z0-9\\s\\-\\._]', ' ', step1)\n",
    "print(step2)\n",
    "print()\n",
    "\n",
    "print(\"Step 3 - Tokenization:\")\n",
    "step3 = word_tokenize(step2)\n",
    "print(step3)\n",
    "print()\n",
    "\n",
    "print(\"Step 4 - Remove stopwords:\")\n",
    "step4 = [token for token in step3 if token not in stop_words and len(token) > 2]\n",
    "print(step4)\n",
    "print()\n",
    "\n",
    "print(\"Step 5 - Stemming:\")\n",
    "step5 = [stemmer.stem(token) for token in step4]\n",
    "print(step5)\n",
    "print()\n",
    "\n",
    "print(\"Final preprocessed text:\")\n",
    "final_text = preprocess_text(sample_text)\n",
    "print(final_text)\n",
    "\n",
    "# Apply preprocessing to datasets\n",
    "print(\"\\nApplying preprocessing to all datasets...\")\n",
    "incidents_df['processed_text'] = incidents_df['text'].apply(preprocess_text)\n",
    "emails_df['processed_text'] = emails_df['text'].apply(preprocess_text)\n",
    "threat_intel_df['processed_text'] = threat_intel_df['text'].apply(preprocess_text)\n",
    "\n",
    "print(\"✅ Preprocessing completed!\")\n",
    "\n",
    "# Compare original vs processed text lengths\n",
    "original_lengths = incidents_df['text'].str.len()\n",
    "processed_lengths = incidents_df['processed_text'].str.len()\n",
    "\n",
    "print(f\"\\nText length comparison:\")\n",
    "print(f\"Original average length: {original_lengths.mean():.1f} characters\")\n",
    "print(f\"Processed average length: {processed_lengths.mean():.1f} characters\")\n",
    "print(f\"Reduction: {(1 - processed_lengths.mean()/original_lengths.mean())*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5569dec3-d5b9-4703-a69f-d7f884d7600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 6: FEATURE ENGINEERING (TF-IDF)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n⚙️ STEP 6: FEATURE ENGINEERING - TF-IDF\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Demonstrate TF-IDF on incident data\n",
    "print(\"Creating TF-IDF features for incident classification...\")\n",
    "\n",
    "# Prepare data for TF-IDF\n",
    "X_text = incidents_df['processed_text']\n",
    "y_type = incidents_df['type']\n",
    "y_severity = incidents_df['severity']\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=1000,        # Limit vocabulary size\n",
    "    min_df=2,                 # Ignore terms that appear in less than 2 documents\n",
    "    max_df=0.8,               # Ignore terms that appear in more than 80% of documents\n",
    "    ngram_range=(1, 2)        # Use unigrams and bigrams\n",
    ")\n",
    "\n",
    "# Fit and transform the text data\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X_text)\n",
    "\n",
    "print(f\"TF-IDF Matrix Shape: {X_tfidf.shape}\")\n",
    "print(f\"Vocabulary Size: {len(tfidf_vectorizer.vocabulary_)}\")\n",
    "\n",
    "# Get feature names\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Analyze top TF-IDF features by incident type\n",
    "print(\"\\nTOP TF-IDF FEATURES BY INCIDENT TYPE:\")\n",
    "for incident_type in incidents_df['type'].unique():\n",
    "    # Get indices for this incident type\n",
    "    type_indices = incidents_df[incidents_df['type'] == incident_type].index\n",
    "    \n",
    "    # Get TF-IDF scores for this type\n",
    "    type_tfidf = X_tfidf[type_indices].mean(axis=0).A1\n",
    "    \n",
    "    # Get top features\n",
    "    top_features_idx = type_tfidf.argsort()[-10:][::-1]\n",
    "    top_features = [(feature_names[i], type_tfidf[i]) for i in top_features_idx]\n",
    "    \n",
    "    print(f\"\\n{incident_type.upper()}:\")\n",
    "    for feature, score in top_features[:5]:\n",
    "        print(f\"  {feature}: {score:.4f}\")\n",
    "\n",
    "# Visualize TF-IDF feature importance\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Get overall top features\n",
    "overall_tfidf = X_tfidf.mean(axis=0).A1\n",
    "top_overall_idx = overall_tfidf.argsort()[-20:][::-1]\n",
    "top_features = [feature_names[i] for i in top_overall_idx]\n",
    "top_scores = [overall_tfidf[i] for i in top_overall_idx]\n",
    "\n",
    "ax.barh(range(len(top_features)), top_scores, color='skyblue')\n",
    "ax.set_yticks(range(len(top_features)))\n",
    "ax.set_yticklabels(top_features)\n",
    "ax.set_xlabel('Average TF-IDF Score')\n",
    "ax.set_title('Top 20 TF-IDF Features Across All Incidents')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7101c8f5-23dd-4dd2-8a77-e5b45428451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 7: SENTIMENT ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n😊 STEP 7: SENTIMENT ANALYSIS FOR SECURITY\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    \"\"\"\n",
    "    Analyze sentiment using TextBlob\n",
    "    Returns polarity (-1 to 1) and subjectivity (0 to 1)\n",
    "    \"\"\"\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity, blob.sentiment.subjectivity\n",
    "\n",
    "def interpret_security_sentiment(polarity, subjectivity):\n",
    "    \"\"\"\n",
    "    Interpret sentiment in security context\n",
    "    \"\"\"\n",
    "    # Map sentiment to security urgency/threat level\n",
    "    if polarity < -0.3:\n",
    "        urgency = \"High\"  # Negative sentiment often indicates threats\n",
    "    elif polarity < 0.1:\n",
    "        urgency = \"Medium\"\n",
    "    else:\n",
    "        urgency = \"Low\"\n",
    "    \n",
    "    # Subjectivity indicates confidence level\n",
    "    if subjectivity > 0.6:\n",
    "        confidence = \"Low\"  # High subjectivity = low confidence\n",
    "    elif subjectivity > 0.3:\n",
    "        confidence = \"Medium\"\n",
    "    else:\n",
    "        confidence = \"High\"\n",
    "    \n",
    "    return urgency, confidence\n",
    "\n",
    "# Analyze sentiment for different datasets\n",
    "print(\"SENTIMENT ANALYSIS ON EMAIL DATASET:\")\n",
    "\n",
    "# Analyze emails\n",
    "email_sentiments = []\n",
    "for _, row in emails_df.iterrows():\n",
    "    polarity, subjectivity = analyze_sentiment(row['text'])\n",
    "    urgency, confidence = interpret_security_sentiment(polarity, subjectivity)\n",
    "    \n",
    "    email_sentiments.append({\n",
    "        'email_id': row['email_id'],\n",
    "        'label': row['label'],\n",
    "        'polarity': polarity,\n",
    "        'subjectivity': subjectivity,\n",
    "        'urgency': urgency,\n",
    "        'confidence': confidence\n",
    "    })\n",
    "\n",
    "sentiment_df = pd.DataFrame(email_sentiments)\n",
    "\n",
    "# Display results\n",
    "print(f\"Average sentiment by email type:\")\n",
    "sentiment_summary = sentiment_df.groupby('label')[['polarity', 'subjectivity']].mean()\n",
    "print(sentiment_summary)\n",
    "\n",
    "print(f\"\\nUrgency distribution by email type:\")\n",
    "urgency_crosstab = pd.crosstab(sentiment_df['label'], sentiment_df['urgency'])\n",
    "print(urgency_crosstab)\n",
    "\n",
    "# Visualize sentiment analysis\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Sentiment polarity by email type\n",
    "sentiment_df.boxplot(column='polarity', by='label', ax=axes[0])\n",
    "axes[0].set_title('Sentiment Polarity by Email Type')\n",
    "axes[0].set_xlabel('Email Type')\n",
    "axes[0].set_ylabel('Polarity (Negative ← → Positive)')\n",
    "\n",
    "# Subjectivity by email type\n",
    "sentiment_df.boxplot(column='subjectivity', by='label', ax=axes[1])\n",
    "axes[1].set_title('Subjectivity by Email Type')\n",
    "axes[1].set_xlabel('Email Type')\n",
    "axes[1].set_ylabel('Subjectivity (Objective ← → Subjective)')\n",
    "\n",
    "# Urgency distribution\n",
    "urgency_crosstab.plot(kind='bar', ax=axes[2], color=['green', 'orange', 'red'])\n",
    "axes[2].set_title('Security Urgency Distribution by Email Type')\n",
    "axes[2].set_xlabel('Email Type')\n",
    "axes[2].set_ylabel('Count')\n",
    "axes[2].legend(title='Urgency Level')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Example sentiment analysis\n",
    "print(\"SENTIMENT ANALYSIS EXAMPLES:\")\n",
    "sample_emails = emails_df.sample(4, random_state=42)\n",
    "for _, row in sample_emails.iterrows():\n",
    "    polarity, subjectivity = analyze_sentiment(row['text'])\n",
    "    urgency, confidence = interpret_security_sentiment(polarity, subjectivity)\n",
    "    \n",
    "    print(f\"\\nEmail: {row['email_id']} (Actual: {row['label']})\")\n",
    "    print(f\"Text: {row['text'][:100]}...\")\n",
    "    print(f\"Sentiment: Polarity={polarity:.3f}, Subjectivity={subjectivity:.3f}\")\n",
    "    print(f\"Security Assessment: Urgency={urgency}, Confidence={confidence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6021af-fb53-4c26-b2b7-6de9cf306cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 8: TOPIC MODELING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n📊 STEP 8: TOPIC MODELING FOR THREAT INTELLIGENCE\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Prepare data for topic modeling\n",
    "threat_intel_texts = threat_intel_df['processed_text'].tolist()\n",
    "\n",
    "# Use CountVectorizer for LDA (works better than TF-IDF)\n",
    "count_vectorizer = CountVectorizer(\n",
    "    max_features=100,\n",
    "    min_df=2,\n",
    "    max_df=0.8,\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "# Create document-term matrix\n",
    "doc_term_matrix = count_vectorizer.fit_transform(threat_intel_texts)\n",
    "\n",
    "print(f\"Document-Term Matrix Shape: {doc_term_matrix.shape}\")\n",
    "\n",
    "# Apply Latent Dirichlet Allocation (LDA)\n",
    "n_topics = 5\n",
    "lda_model = LatentDirichletAllocation(\n",
    "    n_components=n_topics,\n",
    "    random_state=42,\n",
    "    max_iter=100,\n",
    "    learning_method='online'\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "lda_model.fit(doc_term_matrix)\n",
    "\n",
    "# Get feature names\n",
    "feature_names = count_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Display topics\n",
    "print(\"DISCOVERED TOPICS IN THREAT INTELLIGENCE:\")\n",
    "def display_topics(model, feature_names, n_top_words=8):\n",
    "    topics = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_words_idx = topic.argsort()[-n_top_words:][::-1]\n",
    "        top_words = [feature_names[i] for i in top_words_idx]\n",
    "        topics[f\"Topic {topic_idx + 1}\"] = top_words\n",
    "        print(f\"\\nTopic {topic_idx + 1}:\")\n",
    "        print(\", \".join(top_words))\n",
    "    return topics\n",
    "\n",
    "discovered_topics = display_topics(lda_model, feature_names)\n",
    "\n",
    "# Assign topics to documents\n",
    "doc_topic_probs = lda_model.transform(doc_term_matrix)\n",
    "\n",
    "# Find dominant topic for each document\n",
    "dominant_topics = doc_topic_probs.argmax(axis=1)\n",
    "\n",
    "# Add topic assignments to dataframe\n",
    "threat_intel_df['dominant_topic'] = dominant_topics\n",
    "threat_intel_df['topic_probability'] = doc_topic_probs.max(axis=1)\n",
    "\n",
    "print(f\"\\nTOPIC DISTRIBUTION IN THREAT INTELLIGENCE:\")\n",
    "topic_counts = pd.Series(dominant_topics).value_counts().sort_index()\n",
    "for topic_id, count in topic_counts.items():\n",
    "    print(f\"Topic {topic_id + 1}: {count} documents ({count/len(threat_intel_df)*100:.1f}%)\")\n",
    "\n",
    "# Visualize topics\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Topic distribution\n",
    "topic_counts.plot(kind='bar', ax=axes[0], color='lightblue')\n",
    "axes[0].set_title('Topic Distribution in Threat Intelligence')\n",
    "axes[0].set_xlabel('Topic Number')\n",
    "axes[0].set_ylabel('Number of Documents')\n",
    "\n",
    "# Topic probability distribution\n",
    "axes[1].hist(threat_intel_df['topic_probability'], bins=20, color='lightgreen', alpha=0.7)\n",
    "axes[1].set_title('Topic Assignment Confidence Distribution')\n",
    "axes[1].set_xlabel('Probability of Dominant Topic')\n",
    "axes[1].set_ylabel('Number of Documents')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show examples from each topic\n",
    "print(\"\\nEXAMPLE DOCUMENTS BY TOPIC:\")\n",
    "for topic_id in range(n_topics):\n",
    "    topic_docs = threat_intel_df[threat_intel_df['dominant_topic'] == topic_id]\n",
    "    if len(topic_docs) > 0:\n",
    "        sample_doc = topic_docs.iloc[0]\n",
    "        print(f\"\\nTopic {topic_id + 1} Example:\")\n",
    "        print(f\"Document: {sample_doc['report_id']}\")\n",
    "        print(f\"Text: {sample_doc['text']}\")\n",
    "        print(f\"Confidence: {sample_doc['topic_probability']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b0bb51-0f88-4ba7-a164-dd31b208271f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 9: CLASSIFICATION MODEL TRAINING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n🤖 STEP 9: CLASSIFICATION MODEL TRAINING\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Classification Task 1: Incident Type Classification\n",
    "print(\"TASK 1: INCIDENT TYPE CLASSIFICATION\")\n",
    "\n",
    "# Prepare features and labels\n",
    "X = X_tfidf  # TF-IDF features from Step 6\n",
    "y = incidents_df['type']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "\n",
    "# Train multiple models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Naive Bayes': MultinomialNB()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"{name} Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "# Detailed evaluation of best model\n",
    "best_model_name = max(results.keys(), key=lambda k: results[k]['accuracy'])\n",
    "best_model = results[best_model_name]['model']\n",
    "best_predictions = results[best_model_name]['predictions']\n",
    "\n",
    "print(f\"\\nBEST MODEL: {best_model_name}\")\n",
    "print(f\"Accuracy: {results[best_model_name]['accuracy']:.3f}\")\n",
    "\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_test, best_predictions))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, best_predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=incidents_df['type'].unique(),\n",
    "            yticklabels=incidents_df['type'].unique())\n",
    "plt.title(f'Confusion Matrix - {best_model_name}')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Feature importance (for Logistic Regression)\n",
    "if best_model_name == 'Logistic Regression':\n",
    "    print(\"\\nTOP FEATURES BY INCIDENT TYPE:\")\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "    \n",
    "    for i, class_name in enumerate(best_model.classes_):\n",
    "        coefficients = best_model.coef_[i]\n",
    "        top_features_idx = coefficients.argsort()[-10:][::-1]\n",
    "        \n",
    "        print(f\"\\n{class_name.upper()}:\")\n",
    "        for idx in top_features_idx[:5]:\n",
    "            print(f\"  {feature_names[idx]}: {coefficients[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afe5ffc-3e6d-4922-9054-688ee67f191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 10: CLASSIFICATION TASK 2 - EMAIL CLASSIFICATION (FIXED)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n📧 CLASSIFICATION TASK 2: PHISHING EMAIL DETECTION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Prepare email data\n",
    "X_email_text = emails_df['processed_text']\n",
    "y_email = emails_df['label']\n",
    "\n",
    "# Create TF-IDF features for emails\n",
    "email_tfidf = TfidfVectorizer(max_features=500, ngram_range=(1, 2))\n",
    "X_email_tfidf = email_tfidf.fit_transform(X_email_text)\n",
    "\n",
    "# Split email data\n",
    "X_email_train, X_email_test, y_email_train, y_email_test = train_test_split(\n",
    "    X_email_tfidf, y_email, test_size=0.2, random_state=42, stratify=y_email\n",
    ")\n",
    "\n",
    "# Train email classifier\n",
    "email_classifier = LogisticRegression(random_state=42)\n",
    "email_classifier.fit(X_email_train, y_email_train)\n",
    "\n",
    "# Evaluate email classifier\n",
    "y_email_pred = email_classifier.predict(X_email_test)\n",
    "email_accuracy = accuracy_score(y_email_test, y_email_pred)\n",
    "\n",
    "print(f\"Email Classification Accuracy: {email_accuracy:.3f}\")\n",
    "print(\"\\nEmail Classification Report:\")\n",
    "print(classification_report(y_email_test, y_email_pred))\n",
    "\n",
    "# FIXED: Feature importance for email classification (handles binary classification)\n",
    "print(\"\\nTOP FEATURES FOR PHISHING DETECTION:\")\n",
    "feature_names_email = email_tfidf.get_feature_names_out()\n",
    "\n",
    "# For binary classification, LogisticRegression only stores one set of coefficients\n",
    "if len(email_classifier.classes_) == 2:\n",
    "    # Get the coefficients (only one row for binary classification)\n",
    "    coefficients = email_classifier.coef_[0]\n",
    "    \n",
    "    # Positive coefficients indicate the positive class (usually the second class)\n",
    "    # Negative coefficients indicate the negative class (usually the first class)\n",
    "    \n",
    "    print(f\"\\nFeatures indicating '{email_classifier.classes_[1]}' (positive coefficients):\")\n",
    "    top_positive_idx = coefficients.argsort()[-10:][::-1]\n",
    "    for idx in top_positive_idx[:5]:\n",
    "        if coefficients[idx] > 0:\n",
    "            print(f\"  {feature_names_email[idx]}: {coefficients[idx]:.4f}\")\n",
    "    \n",
    "    print(f\"\\nFeatures indicating '{email_classifier.classes_[0]}' (negative coefficients):\")\n",
    "    top_negative_idx = coefficients.argsort()[:10]\n",
    "    for idx in top_negative_idx[:5]:\n",
    "        if coefficients[idx] < 0:\n",
    "            print(f\"  {feature_names_email[idx]}: {coefficients[idx]:.4f}\")\n",
    "else:\n",
    "    # Multi-class case (original code would work)\n",
    "    for i, class_name in enumerate(email_classifier.classes_):\n",
    "        coefficients = email_classifier.coef_[i]\n",
    "        top_features_idx = coefficients.argsort()[-10:][::-1]\n",
    "        \n",
    "        print(f\"\\n{class_name.upper()}:\")\n",
    "        for idx in top_features_idx[:5]:\n",
    "            print(f\"  {feature_names_email[idx]}: {coefficients[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481633dc-e672-48a7-8ffe-519315e8c08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 11: MODEL EVALUATION AND INTERPRETATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n📈 STEP 11: MODEL EVALUATION AND INTERPRETATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create a comprehensive evaluation summary\n",
    "evaluation_summary = {\n",
    "    'Incident Type Classification': {\n",
    "        'Best Model': best_model_name,\n",
    "        'Accuracy': results[best_model_name]['accuracy'],\n",
    "        'Classes': list(incidents_df['type'].unique()),\n",
    "        'Training Samples': X_train.shape[0],\n",
    "        'Test Samples': X_test.shape[0]\n",
    "    },\n",
    "    'Email Classification': {\n",
    "        'Model': 'Logistic Regression',\n",
    "        'Accuracy': email_accuracy,\n",
    "        'Classes': list(emails_df['label'].unique()),\n",
    "        'Training Samples': X_email_train.shape[0],\n",
    "        'Test Samples': X_email_test.shape[0]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"MODEL PERFORMANCE SUMMARY:\")\n",
    "for task, metrics in evaluation_summary.items():\n",
    "    print(f\"\\n{task}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value}\")\n",
    "\n",
    "# Demonstrate model predictions on new data\n",
    "print(\"\\nMODEL PREDICTIONS ON NEW EXAMPLES:\")\n",
    "\n",
    "# New incident examples\n",
    "new_incidents = [\n",
    "    \"Critical ransomware attack detected on file server. Multiple files encrypted with .encrypted extension.\",\n",
    "    \"Employee reported suspicious email requesting password reset. Potential phishing attempt.\",\n",
    "    \"Vulnerability scanner identified SQL injection flaw in web application login form.\",\n",
    "    \"Firewall logs show repeated connection attempts from external IP to SSH port.\"\n",
    "]\n",
    "\n",
    "print(\"\\nINCIDENT TYPE PREDICTIONS:\")\n",
    "for i, incident in enumerate(new_incidents, 1):\n",
    "    # Preprocess\n",
    "    processed = preprocess_text(incident)\n",
    "    \n",
    "    # Vectorize\n",
    "    incident_tfidf = tfidf_vectorizer.transform([processed])\n",
    "    \n",
    "    # Predict\n",
    "    prediction = best_model.predict(incident_tfidf)[0]\n",
    "    probability = best_model.predict_proba(incident_tfidf)[0].max()\n",
    "    \n",
    "    print(f\"\\nExample {i}:\")\n",
    "    print(f\"Text: {incident}\")\n",
    "    print(f\"Predicted Type: {prediction}\")\n",
    "    print(f\"Confidence: {probability:.3f}\")\n",
    "\n",
    "# New email examples\n",
    "new_emails = [\n",
    "    \"URGENT: Your PayPal account has been limited. Click here to restore access immediately!\",\n",
    "    \"Hi team, please review the attached security report and let me know your thoughts.\"\n",
    "]\n",
    "\n",
    "print(\"\\nEMAIL CLASSIFICATION PREDICTIONS:\")\n",
    "for i, email in enumerate(new_emails, 1):\n",
    "    # Preprocess\n",
    "    processed = preprocess_text(email)\n",
    "    \n",
    "    # Vectorize\n",
    "    email_tfidf_vec = email_tfidf.transform([processed])\n",
    "    \n",
    "    # Predict\n",
    "    prediction = email_classifier.predict(email_tfidf_vec)[0]\n",
    "    probability = email_classifier.predict_proba(email_tfidf_vec)[0].max()\n",
    "    \n",
    "    print(f\"\\nExample {i}:\")\n",
    "    print(f\"Text: {email}\")\n",
    "    print(f\"Predicted Label: {prediction}\")\n",
    "    print(f\"Confidence: {probability:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8efa2a2-a4d1-4965-8c83-dde3c3dc64b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 12: BUSINESS IMPACT AND INSIGHTS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n💼 STEP 12: BUSINESS IMPACT AND INSIGHTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calculate business metrics\n",
    "total_incidents = len(incidents_df)\n",
    "total_emails = len(emails_df)\n",
    "processing_time_manual = 45  # minutes per incident\n",
    "processing_time_auto = 0.02  # minutes per incident (1.2 seconds)\n",
    "\n",
    "# Time savings calculation\n",
    "manual_time_hours = (total_incidents * processing_time_manual) / 60\n",
    "auto_time_hours = (total_incidents * processing_time_auto) / 60\n",
    "time_saved_hours = manual_time_hours - auto_time_hours\n",
    "\n",
    "# Cost savings (assuming $50/hour analyst cost)\n",
    "analyst_hourly_rate = 50\n",
    "cost_savings = time_saved_hours * analyst_hourly_rate\n",
    "\n",
    "print(\"BUSINESS IMPACT ANALYSIS:\")\n",
    "print(f\"Total Incidents Processed: {total_incidents}\")\n",
    "print(f\"Manual Processing Time: {manual_time_hours:.1f} hours\")\n",
    "print(f\"Automated Processing Time: {auto_time_hours:.1f} hours\")\n",
    "print(f\"Time Saved: {time_saved_hours:.1f} hours ({time_saved_hours/manual_time_hours*100:.1f}% reduction)\")\n",
    "print(f\"Cost Savings: ${cost_savings:,.2f}\")\n",
    "\n",
    "# Accuracy impact\n",
    "incident_accuracy = results[best_model_name]['accuracy']\n",
    "false_positive_rate = 1 - incident_accuracy\n",
    "\n",
    "print(f\"\\nACCURACY ANALYSIS:\")\n",
    "print(f\"Incident Classification Accuracy: {incident_accuracy:.1%}\")\n",
    "print(f\"Email Classification Accuracy: {email_accuracy:.1%}\")\n",
    "print(f\"Estimated False Positive Rate: {false_positive_rate:.1%}\")\n",
    "\n",
    "# Key insights from topic modeling\n",
    "print(f\"\\nTHREAT INTELLIGENCE INSIGHTS:\")\n",
    "print(f\"Number of Topics Discovered: {n_topics}\")\n",
    "if len(dominant_topics) > 0:\n",
    "    mode_result = pd.Series(dominant_topics).mode()\n",
    "    if len(mode_result) > 0:\n",
    "        print(f\"Most Common Topic: Topic {mode_result.iloc[0] + 1}\")\n",
    "    else:\n",
    "        print(\"Most Common Topic: Unable to determine\")\n",
    "else:\n",
    "    print(\"Most Common Topic: No topics assigned\")\n",
    "print(f\"Average Topic Confidence: {threat_intel_df['topic_probability'].mean():.3f}\")\n",
    "\n",
    "# Recommendations\n",
    "recommendations = [\n",
    "    \"Deploy automated incident classification to reduce analyst workload by 70%\",\n",
    "    \"Implement real-time phishing email detection with 85%+ accuracy\",\n",
    "    \"Use topic modeling to automatically categorize threat intelligence feeds\",\n",
    "    \"Set up sentiment analysis for prioritizing security alerts\",\n",
    "    \"Establish human-in-the-loop workflow for low-confidence predictions\",\n",
    "    \"Regular model retraining (monthly) to adapt to new threat patterns\"\n",
    "]\n",
    "\n",
    "print(f\"\\nRECOMMENDATIONS:\")\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"{i}. {rec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5200bd99-ba15-4e0e-a7f1-fd80ceeb1cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 13: CONCLUSION AND NEXT STEPS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n🎯 STEP 13: CONCLUSION AND NEXT STEPS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"WHAT WE ACCOMPLISHED:\")\n",
    "print(\"✅ Generated realistic synthetic security data\")\n",
    "print(\"✅ Implemented complete text preprocessing pipeline\")\n",
    "print(\"✅ Applied TF-IDF feature engineering\")\n",
    "print(\"✅ Performed sentiment analysis for threat assessment\")\n",
    "print(\"✅ Discovered topics in threat intelligence using LDA\")\n",
    "print(\"✅ Built and evaluated classification models\")\n",
    "print(\"✅ Demonstrated business impact and ROI\")\n",
    "\n",
    "print(\"\\nKEY LEARNINGS:\")\n",
    "key_learnings = [\n",
    "    \"Text preprocessing is crucial for security NLP (removes noise, standardizes format)\",\n",
    "    \"TF-IDF effectively captures important security terms and concepts\",\n",
    "    \"Sentiment analysis can indicate threat urgency and emotional manipulation\",\n",
    "    \"Topic modeling reveals hidden patterns in large text collections\",\n",
    "    \"Simple models (Logistic Regression) can achieve high accuracy on well-preprocessed data\",\n",
    "    \"Binary classification in scikit-learn requires special handling for feature importance\",\n",
    "    \"NLP provides significant ROI through automation and consistency\"\n",
    "]\n",
    "\n",
    "for learning in key_learnings:\n",
    "    print(f\"• {learning}\")\n",
    "\n",
    "print(\"\\nNEXT STEPS FOR PRODUCTION DEPLOYMENT:\")\n",
    "next_steps = [\n",
    "    \"Collect and label real security data (with proper privacy controls)\",\n",
    "    \"Implement robust data pipeline for continuous model training\",\n",
    "    \"Add explainability features (LIME, SHAP) for analyst trust\",\n",
    "    \"Integrate with existing SIEM/SOAR platforms\",\n",
    "    \"Establish monitoring for model drift and performance degradation\",\n",
    "    \"Design human-in-the-loop workflows for edge cases\",\n",
    "    \"Implement adversarial robustness testing\",\n",
    "    \"Develop custom security-domain language models\"\n",
    "]\n",
    "\n",
    "for i, step in enumerate(next_steps, 1):\n",
    "    print(f\"{i}. {step}\")\n",
    "\n",
    "print(\"\\nADDITIONAL LEARNING RESOURCES:\")\n",
    "resources = [\n",
    "    \"Practice with real datasets: MITRE ATT&CK, CVE database, public security feeds\",\n",
    "    \"Explore advanced models: BERT, RoBERTa for security text understanding\",\n",
    "    \"Learn security-specific NLP libraries: spaCy security models, YARA rules\",\n",
    "    \"Study adversarial NLP: how attackers might try to fool your models\",\n",
    "    \"Join communities: security data science groups, NLP conferences\"\n",
    "]\n",
    "\n",
    "for resource in resources:\n",
    "    print(f\"• {resource}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"🏆 CONGRATULATIONS! You've completed the NLP for Security workshop!\")\n",
    "print(\"You now have hands-on experience with the complete ML lifecycle for security text analysis.\")\n",
    "print(\"Keep practicing and building more advanced security NLP solutions!\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Save key results for reference\n",
    "print(\"\\n💾 SAVING RESULTS FOR REFERENCE...\")\n",
    "\n",
    "# Create results summary\n",
    "results_summary = {\n",
    "    'incident_classification_accuracy': results[best_model_name]['accuracy'],\n",
    "    'email_classification_accuracy': email_accuracy,\n",
    "    'time_savings_hours': time_saved_hours,\n",
    "    'cost_savings_dollars': cost_savings,\n",
    "    'topics_discovered': n_topics,\n",
    "    'preprocessing_vocab_reduction': (1 - processed_lengths.mean()/original_lengths.mean())*100\n",
    "}\n",
    "\n",
    "# Display final summary\n",
    "print(\"\\nFINAL RESULTS SUMMARY:\")\n",
    "for metric, value in results_summary.items():\n",
    "    if 'accuracy' in metric:\n",
    "        print(f\"{metric}: {value:.3f}\")\n",
    "    elif 'percentage' in metric or 'reduction' in metric:\n",
    "        print(f\"{metric}: {value:.1f}%\")\n",
    "    elif 'dollars' in metric:\n",
    "        print(f\"{metric}: ${value:,.2f}\")\n",
    "    else:\n",
    "        print(f\"{metric}: {value}\")\n",
    "\n",
    "print(\"\\n✨ Workshop completed successfully! ✨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815c834d-d321-4569-819d-af3efe55d317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
